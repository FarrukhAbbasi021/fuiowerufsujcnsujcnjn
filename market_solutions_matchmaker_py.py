# -*- coding: utf-8 -*-
"""Market_solutions_matchmaker.py.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cr1teBMnNVboePsWsB-tC-6ksbcgSXpq
"""

pip install langchain==0.0.263

pip install openai==0.27.8

pip install pinecone-client==4.1.0

pip install PyPDF2==3.0.1

pip install streamlit==1.25.0

pip install streamlit_chat==0.1.1

pip install streamlit_js_eval==0.1.5

pip install tiktoken==0.4.0

pip install tqdm==4.66.1

pip install typing-extensions==4.7.0

import os
import sys
import time
import openai
import datetime
import pinecone
import streamlit as st
from streamlit_chat import message
from langchain.vectorstores import Pinecone
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQAWithSourcesChain
from langchain.schema import HumanMessage, SystemMessage, AIMessage
from streamlit_js_eval import streamlit_js_eval

try:
    import environment_variables
except ImportError:
    pass

try:
    # Setting page title and header
    st.set_page_config(
        page_title="Market Solution Matchmaker", page_icon=":robot_face:")

    st.markdown("<h1 style='text-align: center;'>Market Solution Matchmaker ðŸ˜¬</h1>",
                unsafe_allow_html=True)

except Exception as e:
    st.error(f"An error occurred: {e}")

# Set API keys and environment
openai_organization = "org-8iWBFHBFb6BxwVhsTSzHxB52"
openai_api_key = "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"

import pinecone
import time
import os
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Pinecone as LangchainPinecone

# Initialize Pinecone client
pinecone_client = pinecone.Pinecone(api_key="faa53568-83bd-4a0c-bb39-6d404d36377f", environment="gcp-starter")

# Define the index name
index_name = "market-solutions"

# Define the spec for the index
spec = {
    "name": "market-solutions",
    "dimension": 1536,
    "metric": "cosine",
    "pod_type": "pod",
    "pod_name": "market-solutions-pod",
    "num_shards": 1,
    "replication_factor": 1
}

try:
    # Try to create the index
    pinecone_client.create_index(name=index_name, dimension=1536, metric="cosine", spec=spec)
except pinecone.exceptions.PineconeException as e:
    # Check the error message to see if it's a 422 error
    if "422" in str(e):
        print(f"Error creating index: {e}")
    else:
        # If the index already exists, catch the exception and continue
        if "already exists" in str(e):
            print(f"Index '{index_name}' already exists. Continuing...")
        else:
            raise

# Connect to the index
index = pinecone_client.Index(index_name)

# Wait a moment for the index to be fully initialized
time.sleep(1)

# Get OpenAI API key from environment variables or set it manually
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') or 'your_openai_api_key_here'

# Define the model name
model_name = 'text-embedding-ada-002'

# Initialize the OpenAI embeddings
embed = OpenAIEmbeddings(
    model=model_name,
    openai_api_key=OPENAI_API_KEY
)

text_field = "text"

# Switch back to the normal index for langchain
vectorstore = LangchainPinecone(
    index, embed.embed_query, text_field
)

# Initialise session state variables
if 'generated' not in st.session_state:
        st.session_state['generated'] = []
if 'past' not in st.session_state:
        st.session_state['past'] = []
if 'messages' not in st.session_state:
        st.session_state['messages'] = [
            {"role": "system", "content": "You are a helpful assistant."}
        ]
if 'model_name' not in st.session_state:
        st.session_state['model_name'] = []
if 'market_solution_list' not in st.session_state:
        st.session_state['market_solution_list'] = []

# Sidebar - let user choose model, show total cost of current conversation, and let user clear the current conversation
# st.sidebar.title("Sidebar")
counter_placeholder = st.sidebar.empty()
# counter_placeholder.write(f"Total cost of this conversation: ${st.session_state['total_cost']:.5f}")
# clear_button = st.sidebar.button("Clear Conversation", key="clear")



st.caption(
            "Model: gpt-3.5-turbo / gpt-4-0125-preview.")

model_name = st.sidebar.radio("Choose a model:", ("GPT-3.5", "GPT-4"))

    # model_name = "GPT-3.5"

    # Map model names to OpenAI model IDs
if model_name == "GPT-3.5":
        model = "gpt-3.5-turbo"
else:
        model = "gpt-4-0125-preview"

    # reset everything
    # if clear_button:
        # st.session_state['generated'] = []
        # st.session_state['past'] = []
        # st.session_state['messages'] = [
        #     {"role": "system", "content": "You are a helpful assistant."}
        # ]
        # st.session_state['model_name'] = []
        # counter_placeholder.write(f"Total cost of this conversation: ${st.session_state['total_cost']:.5f}")

    # generate a response

def generate_response(prompt, selected_year, market_solution_providers, sort_by, sort_order):
        # query = prompt
        # response = ""
        # st.session_state['messages'].append(
        #     {"role": "user", "content": prompt})
        query = prompt
        selected_year = selected_year.strip()
        response = ""
        market_solution_list = []
        market_solution_provider_list = []
        ms_metadata_filter = {}

        if selected_year != "":
            new_metadata = {"year": selected_year}
            ms_metadata_filter.update(new_metadata)

        for market_solution_provider in market_solution_providers:
            market_solution_provider = market_solution_provider.strip()
            if market_solution_provider != "":
                market_solution_provider_list.append(market_solution_provider)

        if len(market_solution_provider_list) > 0:
            new_metadata = {"contributor": {
                "$in": market_solution_provider_list}}
            ms_metadata_filter.update(new_metadata)

        ######################################################
        # docs_and_scores = vectorstore.similarity_search_with_score(
        #     query, k=10,)
        if len(ms_metadata_filter) > 0:
            docs_and_scores = vectorstore.similarity_search_with_score(
                query,
                k=10,
                filter=ms_metadata_filter,
            )
        else:
            docs_and_scores = vectorstore.similarity_search_with_score(
                query,
                k=10,
            )

        raw_market_solution_list = []
        market_solution_list = []
        for doc in docs_and_scores:
            if 'source' in list(doc)[0].metadata:
                source = list(doc)[0].metadata['source']
            else:
                source = ""

            if 'year' in list(doc)[0].metadata:
                year = list(doc)[0].metadata['year']
            else:
                year = 0

            if 'solution_provider' in list(doc)[0].metadata:
                solution_provider = list(
                    doc)[0].metadata['solution_provider']
            else:
                solution_provider = ""

            if 'company_information' in list(doc)[0].metadata:
                company_information = list(
                    doc)[0].metadata['company_information']
            else:
                company_information = ""

            if 'solution' in list(doc)[0].metadata:
                market_solution = list(
                    doc)[0].metadata['solution']
            else:
                market_solution = ""

            if 'key_technology' in list(doc)[0].metadata:
                key_technology = list(
                    doc)[0].metadata['key_technology']
            else:
                key_technology = ""

            if 'contact_person_name' in list(doc)[0].metadata:
                contact_person_name = list(
                    doc)[0].metadata['contact_person_name']
            else:
                contact_person_name = ""

            if 'contact_person_email' in list(doc)[0].metadata:
                contact_person_email = list(
                    doc)[0].metadata['contact_person_email']
            else:
                contact_person_email = ""

            if 'website_url' in list(doc)[0].metadata:
                website_url = list(
                    doc)[0].metadata['website_url']
            else:
                website_url = ""

            if 'contributor' in list(doc)[0].metadata:
                contributor = list(
                    doc)[0].metadata['contributor']
            else:
                contributor = ""

            if 'logo_base64_string' in list(doc)[0].metadata:
                logo_base64_string = list(
                    doc)[0].metadata['logo_base64_string']
            else:
                logo_base64_string = ""

            raw_market_solution = market_solution.strip()
            raw_market_solution = raw_market_solution.lower()
            raw_market_solution = raw_market_solution.replace(" ", "")
            raw_market_solution = raw_market_solution.replace("\n", "")

            if raw_market_solution not in raw_market_solution_list:
                raw_market_solution_list.append(raw_market_solution)

                # st.text(market_solution)
                # st.sidebar.text(doc)
                score = list(doc)[1]
                score = float(score)
                score = score * 100
                # st.text(score)

# Ensure all necessary imports are here
import streamlit as st
import sys
import os

try:
    # Function to generate response and market solution list
    def generate_response(prompt, year, market_solution_provider_list, sort_by, sort_order):
        market_solution_list = []
        score = 75  # Dummy score for demonstration
        source = "Example Source"
        year = "2023"
        solution_provider = "Example Solution Provider"
        company_information = "Example Company Information"
        market_solution = "Example Market Solution"
        key_technology = "Example Key Technology"
        contact_person_name = "Example Contact Person"
        contact_person_email = "example@example.com"
        website_url = "http://example.com"
        logo_base64_string = "ExampleBase64String"
        contributor = "Example Contributor"

        if score >= 70:
            score = str(round(score, 2))
            market_solution_list.append({
                "score": score,
                "source": source,
                "year": year,
                "solution_provider": solution_provider,
                "company_information": company_information,
                "market_solution": market_solution,
                "key_technology": key_technology,
                "contact_person_name": contact_person_name,
                "contact_person_email": contact_person_email,
                "website_url": website_url,
                "logo_base64_string": logo_base64_string,
                "contributor": contributor,
            })

        response = "Generated response text"  # Dummy response text for demonstration
        st.session_state['messages'].append({"role": "assistant", "content": response})

        if sort_by in ["Year", "Curator"]:
            target_column = "year"
            if sort_by == "Curator":
                target_column = "contributor"

            is_reverse_sort = sort_order == "Descending"
            market_solution_list = sorted(
                market_solution_list, key=lambda d: d[target_column.lower()], reverse=is_reverse_sort)

        return response, market_solution_list

    # Initialize session state
    if 'messages' not in st.session_state:
        st.session_state['messages'] = []
    if 'past' not in st.session_state:
        st.session_state['past'] = []
    if 'generated' not in st.session_state:
        st.session_state['generated'] = []
    if 'model_name' not in st.session_state:
        st.session_state['model_name'] = []
    if 'market_solution_list' not in st.session_state:
        st.session_state['market_solution_list'] = []

    # Container for chat history
    response_container = st.container()
    # Container for text box
    container = st.container()

    with container:
        with st.sidebar:
            with st.form("problem-statement-form"):
                year = st.text_input('Year: (Optional)', key="year")
                market_solution_provider_list = st.multiselect(
                    'Market Solutions curated by:', ('', 'CHI-CHISEL', 'IMDA'), key="market_solution_provider_list")
                prompt = st.text_area('Your Problem Statement:', key='prompt')
                sort_by = st.radio("Sort By:", ["None", "Year", "Curator"])
                sort_order = st.radio("Sorting Order:", ["Ascending", "Descending"])
                is_submitted = st.form_submit_button(label="Search")

                if is_submitted and prompt:
                    output, market_solution_list = generate_response(
                        prompt, year, market_solution_provider_list, sort_by, sort_order)
                    st.session_state['past'].append(prompt)
                    st.session_state['generated'].append(output)
                    st.session_state['model_name'].append("Example Model Name")  # Dummy model name for demonstration
                    st.session_state['market_solution_list'].append(market_solution_list)

    if st.session_state['generated']:
        with response_container:
            for i in range(len(st.session_state['generated'])):
                message(st.session_state["past"][i], is_user=True, key=str(i) + '_user')
                if len(st.session_state["market_solution_list"][i]) < 1:
                    st.markdown(f"""<span style="word-wrap:break-word;">No similar market solution found in the system.</span>""", unsafe_allow_html=True)
                else:
                    counter = 0
                    for market_solution_data in st.session_state["market_solution_list"][i]:
                        counter += 1
                        st.markdown(f"""<span style="word-wrap:break-word;">{counter}. <strong>Company name:</strong> {market_solution_data["solution_provider"]}</span> <span style="word-wrap:break-word; font-style: italic;">(Relevance Score: {market_solution_data["score"]}%)</span>""", unsafe_allow_html=True)
                        st.markdown(f"""<img style="border: 1px solid #ddd" src="data:image/jpeg;base64,{market_solution_data["logo_base64_string"]}" width="200" height="100" />""", unsafe_allow_html=True)
                        st.markdown(f"""<span style="word-wrap:break-word;"><strong>Technology:</strong><br>{market_solution_data["key_technology"]}</span>""", unsafe_allow_html=True)
                        st.markdown(f"""<span style="word-wrap:break-word;"><strong>Curated by:</strong><br>{market_solution_data["contributor"]}</span>""", unsafe_allow_html=True)

                        # See More
                        with st.expander("See more"):
                            st.markdown(f"""<span style="word-wrap:break-word;"><strong>Year:</strong> {market_solution_data["year"]}</span>""", unsafe_allow_html=True)
                            st.markdown(f"""<span style="word-wrap:break-word;"><strong>Company information:</strong> {market_solution_data["company_information"]}</span>""", unsafe_allow_html=True)
                            st.markdown(f"""<span style="word-wrap:break-word;"><strong>Solution:</strong> {market_solution_data["market_solution"]}</span>""", unsafe_allow_html=True)
                            st.markdown(f"""<span style="word-wrap:break-word;"><strong>Contact person name:</strong> {market_solution_data["contact_person_name"]}</span>""", unsafe_allow_html=True)
                            st.markdown(f"""<span style="word-wrap:break-word;"><strong>Contact person email:</strong> {market_solution_data["contact_person_email"]}</span>""", unsafe_allow_html=True)
                            st.markdown(f"""<span style="word-wrap:break-word;"><strong>Website:</strong> <a href="{market_solution_data["website_url"]}" target="_blank">{market_solution_data["website_url"]}</a></span>""", unsafe_allow_html=True)

                        st.markdown(f"""<br>""", unsafe_allow_html=True)

except Exception as e:
    st.error('An error has occurred. Please try again.', icon="ðŸš¨")
    if hasattr(e, 'message'):
        error_message = e.message
    else:
        error_message = str(e)
    st.error('ERROR MESSAGE: {}'.format(error_message))
    exc_type, exc_obj, exc_tb = sys.exc_info()
    fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
    st.error(f'Error Type: {exc_type}', icon="ðŸš¨")
    st.error(f'File Name: {fname}', icon="ðŸš¨")
    st.error(f'Line Number: {exc_tb.tb_lineno}', icon="ðŸš¨")

